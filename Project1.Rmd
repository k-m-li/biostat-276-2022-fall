---
title: "Biostat 276 Project 1"
author: "Kelly Li"
date: "1/29/2022"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(gridExtra)
library(lars)
library(mvtnorm)
library(glmnet)
library(kableExtra)
library(plotmo)
library(matrixStats)
library(reshape2)
library(actuar)
knitr::opts_chunk$set(echo = TRUE)
```

##  Sampling from the Banana Distribution

# a) 


## Bayesian Adaptive Lasso

#a) 
```{r}
sima <- rnorm(5000, 0, 1)
plot(density(sima), main = "Marginal Density")
```

# b)
```{r}
lambda2 <- 2
tau2 <- rgamma(5000, shape = 1, rate = lambda2/2)
simb <- rnorm(5000, 0, sqrt(tau2))
plot(density(simb), main = "Beta marginal")
```

# c)
\pretolerance=10000
```{r, out.width = "90%"}
bvec <- c(1, 8, 20, 10000)
marginalplot <- function(n, b){
  lambda <- 1/rgamma(n, 1, b)
  tau2 <- rgamma(n, shape = 1, rate = lambda^2/2)
  sim <- rnorm(n, 0, sqrt(tau2))
  plot <- plot(density(sim), 
               main = paste0("Beta marginal, b = ", b),
               xlim = c(-10, 10))
  save_plot <- recordPlot()
  return(save_plot)
}

plots <- lapply(bvec, marginalplot, n = 5000)

```

# d)
We compute the full conditionals below for use in MCMC implementation:
\begin{flalign*}
    p(\vec{\beta}, \tau_1^2, \dots, \tau_p^2, \sigma^2, \lambda^2 | \vec{y}) &\propto 
    p(\vec{y} | \vec{\beta}, \tau_1^2, \dots, \tau_p^2, \sigma^2, \lambda^2)
    p(\vec{\beta} |  \tau_1^2, \dots, \tau_p^2,) 
    p( \tau_1^2, \dots, \tau_p^2, | \lambda^2)
    p(\lambda^2)
    p(\sigma^2) \\
    \\
    p(\sigma^2 |  \vec{y}) &\propto p(\vec{y} | \vec{\beta}, \tau_1^2, \dots, \tau_p^2, \beta, \lambda^2) \\
    &\propto p(\vec{y} | \vec{\beta}, \tau_1^2, \dots, \tau_p^2, \sigma^2, \lambda^2)p(\sigma^2) \\
    &\propto (\sigma^2)^{\frac{-n}{2}}\exp[\frac{-1}{2\sigma^2}(\vec{y} - X\vec{\beta})^T(\vec{y} - X\vec{\beta})](\sigma^2)^{-0.1-1}\exp(\frac{-0.1}{\sigma^2}) \\
    &= {\sigma^2}^{(-\frac{n}{2} + 0.1)-1}\exp[-\frac{1}{\sigma^2}(0.1 + \frac{1}{2}(\vec{y} - X\vec{\beta})^T(\vec{y} - X\vec{\beta})] \\
    &= \text{Inverse Gamma}(\frac{n}{2} + 0.1, 0.1 + \frac{1}{2}(\vec{y} - X\vec{\beta})^T(\vec{y} - X\vec{\beta})) \\
    \\
    p(\vec{\beta} | \vec{y}) &\propto p(\vec{y} | \vec{\beta}, \tau_1^2, \dots, \tau_p^2, \sigma^2, \lambda^2)(\vec{\beta} |  \tau_1^2, \dots, \tau_p^2,) \\
    &\propto \exp[-\frac{1}{2\sigma^2}(\vec{y} - X\vec{\beta})^T(\vec{y} - X\vec{\beta})]\exp[-\frac{1}{2}\Sigma^{-1}\vec{\beta}^T\vec{\beta}] \text{ for } \Sigma = \text{diag}(\tau_i^2) \\
    &= \exp[-\frac{1}{2\sigma^2}(\vec{y}^T\vec{y} - 2\vec{y}^y(X\vec(\beta))^T + (X\vec{\beta})^T(X\vec{\beta})) - \frac{1}{2}\vec{\beta}^T\Sigma^{-1}\vec{\beta}) \\
    &\propto \exp[-\frac{1}{2}(\vec\beta^T(\frac{X^TX}{\sigma^2} + \Sigma^{-1})\vec\beta) - \frac{1}{2\sigma^2}2(X\vec\beta)^T\vec y] \\
    &= N_p([\frac{X^TX}{\sigma^2} + \Sigma^{-1}]^{-1}\frac{X^T\vec y}{\sigma^2}, [\frac{X^TX}{\sigma^2} + \Sigma^{-1}]^{-1})
    \\
    p(\tau_i^2 | \beta_i, \lambda^2, \sigma^2, \vec y) &\propto p(\beta_i | \tau_i^2)p(\tau_i^2 | \lambda^2) \\
    &\propto \frac{1}{\tau_i}\exp[-\frac{1}{2}(\frac{\beta_i}{\tau_i})^2 - \frac{\lambda^2}{2}\tau_i^2] \\
    &= (\frac{1}{\tau_i^2})^{\frac{1}{2}}\exp[-\frac{1}{2}(\beta^2 (\frac{1}{\tau_i^2}) + \lambda^2(\frac{1}{\frac{1}{\tau_i^2}})]\\
    \intertext{Let $u = \frac{1}{\tau_i^2}$ such that the Jacobian: $\frac{d}{du}(\frac{1}{u}) = -\frac{1}{u^2}$}
    p(e | \beta_i, \lambda) &\propto  u^{\frac{1}{2}}\exp[-\frac{\lambda^2}{2}(\frac{\beta_i^2}{\lambda^2}u + \frac{1}{u})]u^{-2} \\
    &\propto e^{-\frac{3}{2}} \exp[-\frac{\lambda^2}{2}(\frac{\beta_i^2}{\lambda^2}u + \frac{1}{u})] \\
    &= IG([\frac{\lambda^2}{\beta_i^2}]^\frac{1}{2}, \lambda^2) \\
    \\
    p(\lambda_i^2 | \tau_i^2, \vec\beta, \sigma^2, \vec y) &\propto p(\vec\tau | \lambda^2)p(\lambda^2) \\
    &\propto \Pi^{p}_{i=1} \exp[-\frac{\lambda^2}{2}\tau_i^2](\lambda^2)^{a-1}\exp[-b\lambda^2] \\
    &\propto \exp[-(\frac{\sum^p_{i=1}\tau_i^2}{2} + b)\lambda^2](\lambda^2)^{a-1} \\
    &= \text{Gamma}(a, \frac{\sum^p_{i=1}\tau_i^2}{2} + b)
\end{flalign*}

# e)
I will implement a Gibbs Sampler algorithm to sample from the posterior distributions. 
```{r}
gibbs <- function(y = y, X = Xdat,
                  lambda2, tau2,
                  n.sim = 1000, burn = 0.1,
                  a = 1, b = 1, beta, fixlambda = FALSE){
  #Chain information
  n.total <- n.sim*(1.0 + burn)
  n.burn <- n.sim*burn
  
  #Initializing matrices
  betamu.out <- matrix(NA, n.sim, 10)
  beta.out <- matrix(NA, n.sim, 10)
  sigma2.out <- c()
  
  #Data and Parameters
  n <- length(y)
  p <- ncol(X)
  XtX <- t(X) %*% X
  
  for(i in 1:n.total){
    rss <- t(y - X %*% beta)%*%(y - X %*% beta)
    #lambda2
    if(fixlambda == TRUE){
        lambda2 <- lambda2
    } else {
        lambda2 <- rgamma(1, shape = a, rate = sum(tau2)/2 + b)
    }
    #tau2
    for(a in 1:length(beta)){
      tau2[a] <- rinvgauss(1, sqrt(lambda2)/sqrt(beta[a]^2), lambda2)
    }
    tau2 <- 1/tau2
    #sigma2
    shape <- 0.1
    scale <- rss/2 + 0.1
    sigma2 <- 1/rgamma(1, shape = shape, scale = scale)
    #beta
    betavar <- solve(XtX/sigma2 + solve(diag(tau2)))
    betamu <- betavar %*% t(X) %*% y/sigma2
    beta <- rmvnorm(n=1, mean = betamu, sigma = betavar) %>% t()
    if(i > n.burn){
      i1 <- i - n.burn
      betamu.out[i1, ] <- betamu
      beta.out[i1, ] <- beta
      sigma2.out[i1] <- sigma2
    }
  }
 return(list(beta = beta.out, sigma2 = sigma2.out))
}

data("diabetes")
Xdat <- diabetes$x
y <- diabetes$y
betahat <- solve(t(Xdat) %*% Xdat) %*% t(Xdat) %*% y
out <- gibbs(y = y, X = Xdat, n = 1000, burn = 0.1,
             a = 1, b = 1, beta = betahat, lambda2 = 1, tau2 = rep(1, 10))

coeffun <- apply(out$beta, 2, function(x){quantile(x,c(0.16,0.5,0.84))})
coefme <- coeffun[2,]

fit.glm <- glmnet(Xdat, y, intercept = FALSE)
coefglm <- coef(fit.glm, s = min(fit.glm$lambda))
compare <- tibble("My MCMC" = coefme, "Glmnet" = matrix(coefglm[-1]))

kable(compare) %>% kable_styling(full_width = F)

```

# f
```{r, cache = TRUE}
lambdas <- exp(seq(-4, 4, 0.1))^2
out <- lapply(lambdas, function(x)gibbs(y = y, X = Xdat,
                     n.sim = 1000, burn = 0.1,
                     a = 1, b = 1, beta = rep(0, 10), 
                     lambda2 = x, tau2 = rep(1, 10),
                     fixlambda = TRUE))
betas <- lapply(out, `[`, c("beta"))
betas <- lapply(betas, sapply, colMedians)

df <- do.call("cbind", betas)
rownames(df) <- colnames(Xdat)
df <- t(df) %>% as.data.frame() %>% melt()
df$lambda <- rep(seq(-4, 4, 0.1), 10)

ggplot(data = df, aes(lambda, value, color = variable)) +
  geom_line() +
  ggtitle("Custom MCMC path") + xlab("log lambda") + ylab("beta")

plot_glmnet(fit.glm, xvar = "lambda")
```

# g
```{r, cache = TRUE}
df.ab <- data.frame(a = c(1, 5, 10, 1, 5, 10, 1, 5, 10),
                    b = c(1, 1, 1, 5, 5, 5, 10, 10, 10))
out <- apply(df.ab, 1, function(df.ab)gibbs(y = y, X = Xdat,
                     n.sim = 1000, burn = 0.1,
                     a = df.ab[1], b = df.ab[2], beta = betahat, 
                     lambda2 = 1, tau2 = rep(1, 10)))
betas <- lapply(out, `[`, c("beta"))
betas <- lapply(betas, sapply, colMedians)
df <- do.call("cbind", betas)
colnames(df) <- paste0("(",df.ab$a,", ", df.ab$b, ")")
rownames(df) <- colnames(Xdat)
df %>% kable() %>% kable_styling(full_width = F)
```

